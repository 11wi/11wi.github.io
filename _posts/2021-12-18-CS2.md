---
published: true
category: dev
---

# 시작하며

R 과제로 시작해서 Python과 pandas를 넘어 Golang, k8s로 넘어오기까지 매번 모르는 것이 너무나 많았고 번번히 구글링 땜빵만 해왔다.
이번 기회에 내 code가 컴퓨터에서 어떻게 돌아가는지의 개념을 기초부터 정리해본다.
내가 가장 오랫동안 본 `top`에서부터 시작한다.

![img.png](../attachments/cs-top.png)

## top

기본적인 설명은 자료가 많다. <https://sabarada.tistory.com/146>
가장 잘 보이는 cpu, memory 항목을 명확히 이해하자.

## cpu

머신러닝 학습을 빠르게 하려면 어떻게 해야하는지 항상 궁금했다.

cpu는 많이 쓸 수록 좋다. 
python 프로세스는 cpu가 100%로 제한되므로 `multiprocessing`을 통해 프로세스 N개로 나눠
띄울 수 있다. 여기서 spawn, fork 개념이 나온다.
`numpy, sklean`와 같은 좋은 패키지는 `cython nogil`로 100% 제한을 해제한다. <https://github.com/scikit-learn/scikit-learn/blob/844b4be24d20fc42cc13b957374c718956a0db39/sklearn/decomposition/_cdnmf_fast.pyx>
`pytorch`에선 `openmp`를 통해 

cpu의 기본 명령어는 데이터 읽기/쓰기, 가감승제, and, or 연산과 같이 간단하다. 아무리 복잡한 프로그램도 이런 cpu 명령의 조합이다.
별도로 matrix 연산 속도를 위한 SSE, MMX 명령어가 있고 이를 intel mkl 라이브러리에 구현한다. 
`numpy`의 성능은 mkl과 같은 blas에서 온다. 

기본적으로 cpu에게 효율적으로 일을 시킬 수 있는 compiler가 중요하다. <https://sungjjinkang.github.io/c++/computerscience/2021/03/22/SIMD.html> 
동일한 로직도 compiler가 잘하면 성능이 좋아지며 `numba jit compiler`가 있는 이유다.

cpu의 효율은 cache(L1, L2)에 달려있다. 연산 성능만 따지면 cpu는 기가헤르츠 단위의 연산을 할 수 있지만 
연산에 필요한 데이터를 가져오는 속도는 이를 못 받쳐준다. <https://formulusblack.com/blog/compute-performance-distance-of-data-as-a-measure-of-latency/>
따라서 cache 영역에 핏한 데이터로 가공해야 연산 성능이 오른다. 
이러한 전략을 cache miss를 줄인다고 하며, `numexpr`에서 볼 수 있다. <https://numexpr.readthedocs.io/projects/NumExpr3/en/latest/intro.html#>
memory 할당도 cpu의 일이므로 copy보다 inplace update가 더 빠르다.

thread
socket
physical/logical

## memory

atomic 단위가 word이다. SSE도 128 비트 단위로 계산된다.

buffer
cache



### spawn, fork

간략히 spawn은 child에서 생성한 object를 parent에서 볼 수 없지만 fork는 볼 수 있다. 

### jvm, pvm

python도 jvm처럼 pvm이 있다. `*.py`는 byte code로 `__pycache__`에 생성된다. 
pvm은 byte code를 실행한다. `import dis; dis.dis([i for i in range(5)])`는 실제 코드가 어떤 byte code가 되는지 보여준다. 
